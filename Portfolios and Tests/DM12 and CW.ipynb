{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e17cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports and installs ###\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20816d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model predictions ###\n",
    "# Baseline models\n",
    "ols3 = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/OLS/ols_output.parquet\")\n",
    "enet = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/ElasticNet/en_prediction_df.csv\")\n",
    "pcr = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PCR/pcr_prediction_df.csv\")\n",
    "pls = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PLS/pls_prediction_df.csv\")\n",
    "rf = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/RandomForest/rf_prediction_df.csv\")\n",
    "gb = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/GradBoost/gb_prediction_df.csv\")\n",
    "nn1 = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN1/nn1_output.parquet\")\n",
    "nn2 = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN2/nn2_output.parquet\")\n",
    "nn3 = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN3/nn3_output.parquet\")\n",
    "nn4 = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN4/nn4_output.parquet\")\n",
    "\n",
    "# Outsider models\n",
    "ols3_out = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/OLS_outsider/ols_outsider_output.parquet\")\n",
    "enet_out = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/ElasticNet_outsider/en_outsider_output.csv\")\n",
    "pcr_out = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PCR_outsider/pcr_outsider_output.csv\")\n",
    "pls_out = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PLS_outsider/pls_outsider_output.csv\")\n",
    "rf_out = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/RandomForest_outsider/rf_outsider_output.csv\")\n",
    "gb_out = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/GradBoost_outsider/gb_outsider_output.csv\")\n",
    "nn1_out = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN1_outsider/nn1_outsider_output.parquet\")\n",
    "nn2_out = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN2_outsider/nn2_outsider_output.parquet\")\n",
    "nn3_out = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN3_outsider/nn3_outsider_output.parquet\")\n",
    "nn4_out = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN4_outsider/nn4_outsider_output.parquet\")\n",
    "\n",
    "# Insider models\n",
    "ols3_is = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/OLS_insider/ols_insider_output.parquet\")\n",
    "en_is = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/ElasticNet_insider/en_insider_output.csv\")\n",
    "pcr_is = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PCR_insider/pcr_insider_output.csv\")\n",
    "pls_is = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/PLS_insider/pls_insider_output.csv\")\n",
    "rf_is = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/RandomForest_insider/rf_insider_output.csv\")\n",
    "gb_is = pd.read_csv(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/GradBoost_insider/gb_insider_output.csv\")\n",
    "nn1_is = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN1_insider/nn1_insider_output.parquet\")\n",
    "nn2_is = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN2_insider/nn2_insider_output.parquet\")\n",
    "nn3_is = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN3_insider/nn3_insider_output.parquet\")\n",
    "nn4_is = pd.read_parquet(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofCopenhagen/Kandidat/Thesis/4.0 Empirical Results/NN4_insider/nn4_insider_output.parquet\")\n",
    "\n",
    "\n",
    "### Dictionaries for models ###\n",
    "model_dict = {\n",
    "    \"OLS3\": ols3,\n",
    "    \"OLS3 Outsider\": ols3_out,\n",
    "    \"OLS3 Insider\": ols3_is,\n",
    "    \"Elastic Net\": enet,\n",
    "    \"Elastic Net Outsider\": enet_out,\n",
    "    \"Elastic Net Insider\": en_is,\n",
    "    \"PCR\": pcr,\n",
    "    \"PCR Outsider\": pcr_out,\n",
    "    \"PCR Insider\": pcr_is,\n",
    "    \"PLS\": pls,\n",
    "    \"PLS Outsider\": pls_out,\n",
    "    \"PLS Insider\": pls_is,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Random Forest Outsider\": rf_out,\n",
    "    \"Random Forest Insider\": rf_is,\n",
    "    \"Grad Boost\": gb,\n",
    "    \"Grad Boost Outsider\": gb_out,\n",
    "    \"Grad Boost Insider\": gb_is,\n",
    "    \"NN1\": nn1,\n",
    "    \"NN1 Outsider\": nn1_out,\n",
    "    \"NN1 Insider\": nn1_is,\n",
    "    \"NN2\": nn2,\n",
    "    \"NN2 Outsider\": nn2_out,\n",
    "    \"NN2 Insider\": nn2_is,\n",
    "    \"NN3\": nn3,\n",
    "    \"NN3 Outsider\": nn3_out,\n",
    "    \"NN3 Insider\": nn3_is,\n",
    "    \"NN4\": nn4,\n",
    "    \"NN4 Outsider\": nn4_out,\n",
    "    \"NN4 Insider\": nn4_is,\n",
    "}\n",
    "\n",
    "# Instead split\n",
    "baseline_models = {\n",
    "    \"OLS3\": ols3,\n",
    "    \"Elastic Net\": enet,\n",
    "    \"PCR\": pcr,\n",
    "    \"PLS\": pls,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Grad Boost\": gb,\n",
    "    \"NN1\": nn1,\n",
    "    \"NN2\": nn2,\n",
    "    \"NN3\": nn3,\n",
    "    \"NN4\": nn4,\n",
    "}\n",
    "\n",
    "outsider_models = {\n",
    "    \"OLS3\": ols3_out,\n",
    "    \"Elastic Net\": enet_out,\n",
    "    \"PCR\": pcr_out,\n",
    "    \"PLS\": pls_out,\n",
    "    \"Random Forest\": rf_out,\n",
    "    \"Grad Boost\": gb_out,\n",
    "    \"NN1\": nn1_out,\n",
    "    \"NN2\": nn2_out,\n",
    "    \"NN3\": nn3_out,\n",
    "    \"NN4\": nn4_out,\n",
    "}\n",
    "\n",
    "insider_models = {\n",
    "    \"OLS3\": ols3_is,\n",
    "    \"Elastic Net\": en_is,\n",
    "    \"PCR\": pcr_is,\n",
    "    \"PLS\": pls_is,\n",
    "    \"Random Forest\": rf_is,\n",
    "    \"Grad Boost\": gb_is,\n",
    "    \"NN1\": nn1_is,\n",
    "    \"NN2\": nn2_is,\n",
    "    \"NN3\": nn3_is,\n",
    "    \"NN4\": nn4_is,\n",
    "}\n",
    "\n",
    "# All to datetime\n",
    "for model_name in model_dict.keys():\n",
    "    model_dict[model_name][\"month\"] = pd.to_datetime(model_dict[model_name][\"month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c432b",
   "metadata": {},
   "source": [
    "DM12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newey_west_se_mean(x, lags=4):\n",
    "    \"\"\"\n",
    "    Newey–West standard error of the mean of a time series x_t.\n",
    "    Implemented via OLS on a constant with HAC covariance.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"x must be a 1D array\")\n",
    "\n",
    "    T = len(x)\n",
    "    if T == 0:\n",
    "        raise ValueError(\"Empty series\")\n",
    "\n",
    "    X = np.ones((T, 1))\n",
    "    model = sm.OLS(x, X).fit(\n",
    "        cov_type=\"HAC\",\n",
    "        cov_kwds={\"maxlags\": lags}\n",
    "    )\n",
    "\n",
    "    # SE of intercept = NW SE of the mean\n",
    "    return float(model.bse[0])\n",
    "\n",
    "\n",
    "def dm_panel_gkx(\n",
    "    df,\n",
    "    y_col,\n",
    "    pred1_col,\n",
    "    pred2_col,\n",
    "    time_col=\"month\",\n",
    "    lags=4,\n",
    "    one_sided=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Panel Diebold–Mariano statistic following Gu, Kelly & Xiu (2020).\n",
    "\n",
    "    Tests:\n",
    "        H0: E[d_t] = 0\n",
    "\n",
    "    where:\n",
    "        d_t = (1 / N_t) * sum_i [ (e1_{i,t})^2 - (e2_{i,t})^2 ]\n",
    "\n",
    "    Interpretation:\n",
    "        DM < 0  -> model 1 has lower MSPE\n",
    "        DM > 0  -> model 2 has lower MSPE\n",
    "    \"\"\"\n",
    "\n",
    "    # Defensive copy\n",
    "    df = df[[y_col, pred1_col, pred2_col, time_col]].dropna().copy()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input DataFrame is empty after dropping NaNs\")\n",
    "\n",
    "    # Forecast errors\n",
    "    df[\"e1\"] = df[y_col] - df[pred1_col]\n",
    "    df[\"e2\"] = df[y_col] - df[pred2_col]\n",
    "\n",
    "    # Squared-error difference at stock level\n",
    "    df[\"diff_sq\"] = df[\"e1\"]**2 - df[\"e2\"]**2\n",
    "\n",
    "    # Cross-sectional average per period\n",
    "    d_t = (\n",
    "        df.groupby(time_col, sort=True)[\"diff_sq\"]\n",
    "          .mean()\n",
    "    )\n",
    "\n",
    "    d_series = d_t.values\n",
    "    T = len(d_series)\n",
    "\n",
    "    if T < 5:\n",
    "        raise ValueError(\"Too few time periods for reliable inference\")\n",
    "\n",
    "    # Mean loss differential\n",
    "    d_bar = float(d_series.mean())\n",
    "\n",
    "    # Newey–West SE of mean\n",
    "    se_dbar = newey_west_se_mean(d_series, lags=lags)\n",
    "\n",
    "    dm_stat = d_bar / se_dbar\n",
    "\n",
    "    # Asymptotic N(0,1)\n",
    "    if one_sided:\n",
    "        # H1: model 2 better than model 1\n",
    "        p_value = 1.0 - norm.cdf(dm_stat)\n",
    "    else:\n",
    "        p_value = 2.0 * (1.0 - norm.cdf(abs(dm_stat)))\n",
    "\n",
    "    return {\n",
    "        \"dm_stat\": float(dm_stat),\n",
    "        \"p_value\": float(p_value),\n",
    "        \"d_bar\": d_bar,\n",
    "        \"d_t\": d_t,\n",
    "        \"T\": T,\n",
    "    }\n",
    "\n",
    "\n",
    "def dm_matrix_gkx(\n",
    "    model_dict_subset,\n",
    "    y_col=\"ret_excess\",\n",
    "    pred_col=\"pred_ret_excess\",\n",
    "    time_col=\"month\",\n",
    "    lags=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Construct a pairwise GKX-style DM matrix for a given set of models.\n",
    "    \"\"\"\n",
    "\n",
    "    model_names = list(model_dict_subset.keys())\n",
    "    n = len(model_names)\n",
    "\n",
    "    DM = np.full((n, n), np.nan)\n",
    "    PV = np.full((n, n), np.nan)\n",
    "\n",
    "    for i, model_i in enumerate(model_names):\n",
    "        for j, model_j in enumerate(model_names):\n",
    "\n",
    "            if i == j:\n",
    "                DM[i, j] = 0.0\n",
    "                PV[i, j] = np.nan\n",
    "                continue\n",
    "\n",
    "            df_i = model_dict_subset[model_i]\n",
    "            df_j = model_dict_subset[model_j]\n",
    "\n",
    "            # Merge on (permno, month)\n",
    "            df = (\n",
    "                df_i[[\"permno\", time_col, y_col, pred_col]]\n",
    "                .rename(columns={pred_col: \"pred1\"})\n",
    "                .merge(\n",
    "                    df_j[[\"permno\", time_col, pred_col]]\n",
    "                    .rename(columns={pred_col: \"pred2\"}),\n",
    "                    on=[\"permno\", time_col],\n",
    "                    how=\"inner\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            res = dm_panel_gkx(\n",
    "                df,\n",
    "                y_col=y_col,\n",
    "                pred1_col=\"pred1\",\n",
    "                pred2_col=\"pred2\",\n",
    "                time_col=time_col,\n",
    "                lags=lags,\n",
    "                one_sided=True,\n",
    "            )\n",
    "\n",
    "            DM[i, j] = res[\"dm_stat\"]\n",
    "            PV[i, j] = res[\"p_value\"]\n",
    "\n",
    "    dm_df = pd.DataFrame(DM, index=model_names, columns=model_names)\n",
    "    pv_df = pd.DataFrame(PV, index=model_names, columns=model_names)\n",
    "\n",
    "    return dm_df, pv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca56997",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_base, pv_base = dm_matrix_gkx(baseline_models)\n",
    "dm_out,  pv_out  = dm_matrix_gkx(outsider_models)\n",
    "dm_in,   pv_in   = dm_matrix_gkx(insider_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline DM statistics\")\n",
    "print(dm_base.round(2))\n",
    "print(\"\\nBaseline p-values\")\n",
    "print(pv_base.round(3))\n",
    "\n",
    "print(\"\\nOutsider DM statistics\")\n",
    "print(dm_out.round(2))\n",
    "print(\"\\nOutsider p-values\")\n",
    "print(pv_out.round(3))\n",
    "\n",
    "print(\"\\nInsider DM statistics\")\n",
    "print(dm_in.round(2))\n",
    "print(\"\\nInsider p-values\")\n",
    "print(pv_in.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stars(dm_df, pval_df):\n",
    "    \"\"\"\n",
    "    Append significance stars to DM statistics based on p-values.\n",
    "\n",
    "    *** p < 0.01\n",
    "    **  p < 0.05\n",
    "    *   p < 0.10\n",
    "    \"\"\"\n",
    "    dm_star = dm_df.copy().astype(object)\n",
    "\n",
    "    for i in dm_df.index:\n",
    "        for j in dm_df.columns:\n",
    "            if pd.isna(dm_df.loc[i, j]):\n",
    "                dm_star.loc[i, j] = \"\"\n",
    "                continue\n",
    "\n",
    "            p = pval_df.loc[i, j]\n",
    "            val = dm_df.loc[i, j]\n",
    "\n",
    "            if pd.isna(p):\n",
    "                dm_star.loc[i, j] = f\"{val:.2f}\"\n",
    "            elif p < 0.01:\n",
    "                dm_star.loc[i, j] = f\"{val:.2f}***\"\n",
    "            elif p < 0.05:\n",
    "                dm_star.loc[i, j] = f\"{val:.2f}**\"\n",
    "            elif p < 0.10:\n",
    "                dm_star.loc[i, j] = f\"{val:.2f}*\"\n",
    "            else:\n",
    "                dm_star.loc[i, j] = f\"{val:.2f}\"\n",
    "\n",
    "    return dm_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68df316",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_base_star = add_stars(dm_base, pv_base)\n",
    "dm_out_star  = add_stars(dm_out,  pv_out)\n",
    "dm_in_star   = add_stars(dm_in,   pv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57226f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline DM (with significance)\")\n",
    "print(dm_base_star)\n",
    "\n",
    "print(\"\\nOutsider DM (with significance)\")\n",
    "print(dm_out_star)\n",
    "\n",
    "print(\"\\nInsider DM (with significance)\")\n",
    "print(dm_in_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a0c59",
   "metadata": {},
   "source": [
    "CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df88162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newey–West standard error of the mean\n",
    "\n",
    "def newey_west_se_mean(x, lags=4):\n",
    "    \"\"\"\n",
    "    Newey–West standard error of the mean of a time series.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.ndim != 1 or len(x) == 0:\n",
    "        raise ValueError(\"Input must be a non-empty 1D array\")\n",
    "\n",
    "    X = np.ones((len(x), 1))\n",
    "    res = sm.OLS(x, X).fit(\n",
    "        cov_type=\"HAC\",\n",
    "        cov_kwds={\"maxlags\": lags}\n",
    "    )\n",
    "\n",
    "    return float(res.bse[0])\n",
    "\n",
    "\n",
    "# Clark–West panel test (GKX-consistent)\n",
    "def clark_west_panel(\n",
    "    df,\n",
    "    y_col=\"ret_excess\",\n",
    "    pred_base_col=\"pred_base\",\n",
    "    pred_aug_col=\"pred_aug\",\n",
    "    time_col=\"month\",\n",
    "    lags=4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Clark–West test for nested models in a panel setting.\n",
    "\n",
    "    H0: Augmented model does NOT improve MSPE\n",
    "    H1: Augmented model improves MSPE\n",
    "\n",
    "    One-sided test.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[[y_col, pred_base_col, pred_aug_col, time_col]].dropna().copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Empty DataFrame after dropping NaNs\")\n",
    "\n",
    "    e_base = df[y_col] - df[pred_base_col]\n",
    "    e_aug  = df[y_col] - df[pred_aug_col]\n",
    "\n",
    "    # Clark–West adjusted loss differential\n",
    "    df[\"cw_diff\"] = (\n",
    "        e_base**2\n",
    "        - (e_aug**2 - (df[pred_aug_col] - df[pred_base_col])**2)\n",
    "    )\n",
    "\n",
    "    # Cross-sectional average per period\n",
    "    f_t = (\n",
    "        df.groupby(time_col, sort=True)[\"cw_diff\"]\n",
    "          .mean()\n",
    "          .sort_index()\n",
    "    )\n",
    "\n",
    "    f = f_t.values\n",
    "    if len(f) < 10:\n",
    "        raise ValueError(\"Too few time periods for CW inference\")\n",
    "\n",
    "    f_bar = float(f.mean())\n",
    "    se_f  = newey_west_se_mean(f, lags=lags)\n",
    "\n",
    "    cw_stat = f_bar / se_f\n",
    "    p_value = 1.0 - norm.cdf(cw_stat)   # one-sided\n",
    "\n",
    "    return {\n",
    "        \"cw_stat\": float(cw_stat),\n",
    "        \"p_value\": float(p_value),\n",
    "    }\n",
    "\n",
    "# Significance stars\n",
    "def star(p):\n",
    "    if p < 0.01:\n",
    "        return \"***\"\n",
    "    elif p < 0.05:\n",
    "        return \"**\"\n",
    "    elif p < 0.10:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Clark–West tests: Baseline -> Outsider and Baseline -> Insider\n",
    "results = []\n",
    "\n",
    "for model_name in baseline_models.keys():\n",
    "\n",
    "    base = baseline_models[model_name]\n",
    "    out  = outsider_models[model_name]\n",
    "    ins  = insider_models[model_name]\n",
    "\n",
    "    # Baseline -> Outsider\n",
    "    df_out = (\n",
    "        base[[\"permno\", \"month\", \"ret_excess\", \"pred_ret_excess\"]]\n",
    "        .rename(columns={\"pred_ret_excess\": \"pred_base\"})\n",
    "        .merge(\n",
    "            out[[\"permno\", \"month\", \"pred_ret_excess\"]]\n",
    "            .rename(columns={\"pred_ret_excess\": \"pred_aug\"}),\n",
    "            on=[\"permno\", \"month\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    res_out = clark_west_panel(df_out)\n",
    "\n",
    "    # Baseline -> Insider\n",
    "    df_ins = (\n",
    "        base[[\"permno\", \"month\", \"ret_excess\", \"pred_ret_excess\"]]\n",
    "        .rename(columns={\"pred_ret_excess\": \"pred_base\"})\n",
    "        .merge(\n",
    "            ins[[\"permno\", \"month\", \"pred_ret_excess\"]]\n",
    "            .rename(columns={\"pred_ret_excess\": \"pred_aug\"}),\n",
    "            on=[\"permno\", \"month\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    res_ins = clark_west_panel(df_ins)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"CW Baseline→Outsider\": res_out[\"cw_stat\"],\n",
    "        \"p Baseline→Outsider\": res_out[\"p_value\"],\n",
    "        \"CW Baseline→Insider\": res_ins[\"cw_stat\"],\n",
    "        \"p Baseline→Insider\": res_ins[\"p_value\"],\n",
    "    })\n",
    "\n",
    "\n",
    "# Final table\n",
    "cw_df = pd.DataFrame(results).set_index(\"Model\")\n",
    "\n",
    "cw_table = pd.DataFrame({\n",
    "    \"Baseline → Outsider\": [\n",
    "        f\"{cw_df.loc[m,'CW Baseline→Outsider']:.2f}{star(cw_df.loc[m,'p Baseline→Outsider'])}\"\n",
    "        for m in cw_df.index\n",
    "    ],\n",
    "    \"Baseline → Insider\": [\n",
    "        f\"{cw_df.loc[m,'CW Baseline→Insider']:.2f}{star(cw_df.loc[m,'p Baseline→Insider'])}\"\n",
    "        for m in cw_df.index\n",
    "    ],\n",
    "}, index=cw_df.index)\n",
    "\n",
    "print(cw_table)\n",
    "\n",
    "# Assume `results` is already created as in your code\n",
    "\n",
    "cw_df = pd.DataFrame(results).set_index(\"Model\")\n",
    "\n",
    "pval_table = pd.DataFrame({\n",
    "    \"Baseline → Outsider (p)\": cw_df[\"p Baseline→Outsider\"],\n",
    "    \"Baseline → Insider (p)\":  cw_df[\"p Baseline→Insider\"],\n",
    "}, index=cw_df.index)\n",
    "\n",
    "print(pval_table.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
