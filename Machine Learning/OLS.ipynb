{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb07238",
   "metadata": {},
   "source": [
    "# 0. Preliminary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q numpy pandas tqdm scikit-learn fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05580453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_split(\n",
    "    df: pd.DataFrame,\n",
    "    train_size: int,\n",
    "    val_size: int,\n",
    "    test_size: int,\n",
    "    step_size: int,\n",
    "    start_date: str | None = None,\n",
    "    end_date: str | None = None,\n",
    "):\n",
    "    \"\"\"Expanding window split for time series data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'month' column in datetime format.\n",
    "        train_size (int): Number of months to include in the training set.\n",
    "        val_size (int): Number of months to include in the validation set.\n",
    "        test_size (int): Number of months to include in the test set.\n",
    "        step_size (int): Number of months to step forward for each iteration.\n",
    "        start_date (str | None, optional): Start date for the data split. Defaults to None.\n",
    "        end_date (str | None, optional): End date for the data split. Defaults to None.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If 'month' column is not in datetime format.\n",
    "\n",
    "    Yields:\n",
    "        train, val, test (pd.DataFrame): DataFrames containing the train, validation, and test sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure 'month' column is in datetime format\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[\"month\"]):\n",
    "        raise TypeError(\"'month' column must be in datetime format\")\n",
    "\n",
    "    # Apply date filters if provided\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    \n",
    "    if start_date:\n",
    "        mask &= df[\"month\"] >= pd.Timestamp(start_date)\n",
    "    if end_date:\n",
    "        mask &= df[\"month\"] <= pd.Timestamp(end_date)\n",
    "\n",
    "    months = sorted(df.loc[mask, \"month\"].unique())\n",
    "\n",
    "    # Set end index\n",
    "    end_idx = train_size + val_size + test_size + 1\n",
    "    \n",
    "    # Create a while loop to iterate until the end index exceeds the number of unique months\n",
    "    while end_idx <= len(months):\n",
    "        train_months = months[: end_idx - (val_size + test_size)]\n",
    "        val_months   = months[end_idx - (val_size + test_size) : end_idx - test_size]\n",
    "        test_months  = months[end_idx - test_size : end_idx]\n",
    "\n",
    "        # Slice firm-month panel\n",
    "        train = df[df[\"month\"].isin(train_months)]\n",
    "        val = df[df[\"month\"].isin(val_months)]\n",
    "        test = df[df[\"month\"].isin(test_months)]\n",
    "\n",
    "        # Stream one result at a time\n",
    "        yield train, val, test\n",
    "\n",
    "        # Expand by step_size months\n",
    "        end_idx += step_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b5da16",
   "metadata": {},
   "source": [
    "# 1. OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 4. OLS REGRESSION FUNCTION (FIXED, SELF-CONTAINED)\n",
    "# ======================================================\n",
    "def OLS_regression(path, features=None, use_all_features=False, target=\"ret_excess\", \n",
    "                   start_year=None, end_year=None, train_size=60, \n",
    "                   val_size=36, test_size=12, step_size=12):\n",
    "    \"\"\"\n",
    "    OLS rolling expanding-window regression.\n",
    "    Loads data from `path`, filters by start/end year, and returns predictions + R².\n",
    "    \"\"\"\n",
    "\n",
    "    # ================== LOAD DATA (INLINE LOAD_DATA) ==================\n",
    "    df = pd.read_parquet(path)\n",
    "\n",
    "    # ensure month is datetime\n",
    "    if \"month\" not in df.columns:\n",
    "        raise KeyError(\"'month' column not found in data.\")\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df[\"month\"]):\n",
    "        df[\"month\"] = pd.to_datetime(df[\"month\"])\n",
    "\n",
    "    # apply year filters\n",
    "    if start_year is not None:\n",
    "        df = df[df[\"month\"] >= pd.Timestamp(f\"{start_year}-01-01\")]\n",
    "    if end_year is not None:\n",
    "        df = df[df[\"month\"] <= pd.Timestamp(f\"{end_year}-12-31\")]\n",
    "    # ================== END LOAD DATA PART ==================\n",
    "\n",
    "    # choose feature set\n",
    "    if use_all_features:\n",
    "        features = [c for c in df.columns if c not in EXCLUDE_COLS + [target]]\n",
    "        print(f\"Using ALL {len(features)} features.\")\n",
    "    elif not features:\n",
    "        raise ValueError(\"Must specify `features` or set `use_all_features=True`.\")\n",
    "\n",
    "    df = df.dropna(subset=features + [target])\n",
    "    df[features + [target]] = df[features + [target]].astype(\"float32\")\n",
    "\n",
    "    # generator\n",
    "    splits = expanding_window_split(\n",
    "        df, train_size, val_size, test_size, step_size,\n",
    "        start_date=f\"{start_year}-01-01\" if start_year else None,\n",
    "        end_date=f\"{end_year}-12-31\" if end_year else None\n",
    "    )\n",
    "\n",
    "    # now also keep cik, prc, shrout, mktcap_lag\n",
    "    results = {\n",
    "        \"y_tests\":    [],\n",
    "        \"r2_window\":  {},\n",
    "        \"permno\":     [],\n",
    "        \"month\":      [],\n",
    "        \"cik\":        [],\n",
    "        \"prc\":        [],\n",
    "        \"shrout\":     [],\n",
    "        \"mktcap_lag\": [],\n",
    "    }\n",
    "\n",
    "    # rolling loop\n",
    "    for i, (train, val, test) in enumerate(splits, 1):\n",
    "\n",
    "        X_fit = np.concatenate([train[features].values, val[features].values])\n",
    "        y_fit = np.concatenate([train[target].values, val[target].values])\n",
    "\n",
    "        X_test = test[features].values\n",
    "        y_test = test[target].values\n",
    "\n",
    "        ols = LinearRegression(fit_intercept=True).fit(X_fit, y_fit)\n",
    "        y_pred = ols.predict(X_test)\n",
    "\n",
    "        # store meta info for later saving\n",
    "        results[\"permno\"].append(test[\"permno\"].values)\n",
    "        results[\"month\"].append(test[\"month\"].values)\n",
    "        results[\"cik\"].append(test[\"cik\"].values)\n",
    "        results[\"prc\"].append(test[\"prc\"].values)\n",
    "        results[\"shrout\"].append(test[\"shrout\"].values)\n",
    "        results[\"mktcap_lag\"].append(test[\"mktcap_lag\"].values)\n",
    "\n",
    "        results[\"y_tests\"].append((y_test, y_pred))\n",
    "\n",
    "        label = test[\"month\"].dt.strftime(\"%Y-%m\").iloc[0]\n",
    "        r2 = 1 - np.sum((y_test - y_pred)**2) / np.sum(y_test**2)\n",
    "        results[\"r2_window\"][f\"R2.{label}\"] = r2\n",
    "\n",
    "        print(f\"[{i:02d}] {label} | R²(test) = {r2:.2%}\")\n",
    "\n",
    "    # full-sample R²\n",
    "    all_y = np.concatenate([y for y, _ in results[\"y_tests\"]])\n",
    "    all_pred = np.concatenate([p for _, p in results[\"y_tests\"]])\n",
    "    results[\"R2_full\"] = 1 - np.sum((all_y - all_pred)**2) / np.sum(all_y**2)\n",
    "\n",
    "    # save metadata\n",
    "    results[\"features\"]   = features\n",
    "    results[\"start_year\"] = start_year\n",
    "    results[\"end_year\"]   = end_year\n",
    "\n",
    "    print(f\"\\n=== Full OOS R² (OLS): {results['R2_full']:.2%} ===\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f6fe36",
   "metadata": {},
   "source": [
    "## OLS without insider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c806a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline data path\n",
    "path = \"/work/Thesis/Data/finalized_true.parquet\"\n",
    "\n",
    "res_ols_3 = OLS_regression(\n",
    "    path=path,  \n",
    "    features=[\"char_mvel1\", \"char_mom12m\", \"char_bm\"],\n",
    "    use_all_features=False,\n",
    "    target=\"ret_excess\",\n",
    "    start_year=2005,\n",
    "    end_year=2021,\n",
    "    train_size=60,\n",
    "    val_size=36,\n",
    "    test_size=12,\n",
    "    step_size=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 6. SAVE OLS OUTPUTS\n",
    "# ======================================================\n",
    "y_tests     = res_ols_3[\"y_tests\"]\n",
    "permno_list = res_ols_3[\"permno\"]\n",
    "month_list  = res_ols_3[\"month\"]\n",
    "\n",
    "y_true = np.concatenate([y for (y, _) in y_tests])\n",
    "y_pred = np.concatenate([yhat for (_, yhat) in y_tests])\n",
    "permno = np.concatenate(permno_list)\n",
    "months = pd.to_datetime(np.concatenate(month_list))\n",
    "\n",
    "df_ols = pd.DataFrame({\n",
    "    \"permno\": permno,\n",
    "    \"month\": months,\n",
    "    \"y_true\": y_true,\n",
    "    \"ols_y_pred\": y_pred,\n",
    "})\n",
    "\n",
    "print(\"\\n===== OLS output preview =====\")\n",
    "print(df_ols.head())\n",
    "print(\"=================================\\n\")\n",
    "\n",
    "df_ols.to_parquet(\"OLS_output.parquet\", index=False)\n",
    "print(\"Saved OLS_output.parquet\")\n",
    "\n",
    "# Save R² JSON\n",
    "r2_metrics_ols = {\n",
    "    \"model\": \"OLS (baseline)\",\n",
    "    \"R2_full\": float(res_ols_3[\"R2_full\"]),\n",
    "    \"R2_window\": {k: float(v) for k, v in res_ols_3[\"r2_window\"].items()},\n",
    "    \"start_year\": res_ols_3[\"start_year\"],\n",
    "    \"end_year\": res_ols_3[\"end_year\"],\n",
    "    \"features\": res_ols_3[\"features\"],\n",
    "}\n",
    "\n",
    "with open(\"OLS_R2.json\", \"w\") as f:\n",
    "    json.dump(r2_metrics_ols, f, indent=2)\n",
    "\n",
    "print(\"Saved OLS_R2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 6. SAVE OLS OUTPUTS (NN1-style columns)\n",
    "# ======================================================\n",
    "y_tests      = res_ols_3[\"y_tests\"]\n",
    "permno_list  = res_ols_3[\"permno\"]\n",
    "month_list   = res_ols_3[\"month\"]\n",
    "cik_list     = res_ols_3[\"cik\"]\n",
    "prc_list     = res_ols_3[\"prc\"]\n",
    "shrout_list  = res_ols_3[\"shrout\"]\n",
    "mktcap_list  = res_ols_3[\"mktcap_lag\"]\n",
    "\n",
    "y_true       = np.concatenate([y for (y, _) in y_tests])\n",
    "y_pred       = np.concatenate([yhat for (_, yhat) in y_tests])\n",
    "permno       = np.concatenate(permno_list)\n",
    "months       = pd.to_datetime(np.concatenate(month_list))\n",
    "cik          = np.concatenate(cik_list)\n",
    "prc          = np.concatenate(prc_list)\n",
    "shrout       = np.concatenate(shrout_list)\n",
    "mktcap_lag   = np.concatenate(mktcap_list)\n",
    "\n",
    "df_ols = pd.DataFrame({\n",
    "    \"month\":           months,\n",
    "    \"cik\":             cik,\n",
    "    \"permno\":          permno,\n",
    "    \"ret_excess\":      y_true,          # same name as NN1\n",
    "    \"prc\":             prc,\n",
    "    \"shrout\":          shrout,\n",
    "    \"mktcap_lag\":      mktcap_lag,\n",
    "    \"pred_ret_excess\": y_pred,          # same name as NN1\n",
    "})\n",
    "\n",
    "print(\"\\n===== OLS output preview =====\")\n",
    "print(df_ols.head())\n",
    "print(\"=================================\\n\")\n",
    "\n",
    "df_ols.to_parquet(\"ols_output.parquet\", index=False)\n",
    "print(\"Saved ols_output.parquet\")\n",
    "\n",
    "# Save R² JSON (unchanged)\n",
    "r2_metrics_ols = {\n",
    "    \"model\": \"ols (baseline)\",\n",
    "    \"R2_full\": float(res_ols_3[\"R2_full\"]),\n",
    "    \"R2_window\": {k: float(v) for k, v in res_ols_3[\"r2_window\"].items()},\n",
    "    \"start_year\": res_ols_3[\"start_year\"],\n",
    "    \"end_year\": res_ols_3[\"end_year\"],\n",
    "    \"features\": res_ols_3[\"features\"],\n",
    "}\n",
    "\n",
    "with open(\"ols_R2.json\", \"w\") as f:\n",
    "    json.dump(r2_metrics_ols, f, indent=2)\n",
    "\n",
    "print(\"Saved ols_R2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa763ce9",
   "metadata": {},
   "source": [
    "## OLS with insider trading (Outsider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline data path\n",
    "path = \"/work/Thesis/Data/2. Outsider/with_outsider.parquet\"\n",
    "\n",
    "res_ols_outsider = OLS_regression(\n",
    "    path=path,  \n",
    "    features=[\"char_mvel1\", \n",
    "    \"char_mom12m\",\n",
    "    \"char_bm\",\n",
    "    \"is_txn_purchase_x_is_tit_ceo\",\n",
    "    \"is_txn_purchase_x_is_tit_cfo\",\n",
    "    \"is_txn_purchase_x_is_tit_coo\",\n",
    "    \"is_txn_purchase_x_is_tit_director\",\n",
    "    \"is_txn_purchase_x_is_tit_other_officer\",\n",
    "    \"is_txn_purchase_x_is_tit_vice_president\",\n",
    "    \"is_txn_sell_x_is_tit_ceo\",\n",
    "    \"is_txn_sell_x_is_tit_ten_percent_owner\",\n",
    "    \"is_opp_buy\",\n",
    "    \"is_opp_sell\",\n",
    "    \"is_rtn_buy\",\n",
    "    \"is_rtn_sell\",\n",
    "    \"is_npr_volume\",\n",
    "    \"is_net_cluster\",\n",
    "    ],\n",
    "    use_all_features=False,\n",
    "    target=\"ret_excess\",\n",
    "    start_year=2005,\n",
    "    end_year=2021,\n",
    "    train_size=60,\n",
    "    val_size=36,\n",
    "    test_size=12,\n",
    "    step_size=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Rename for convenience\n",
    "res = res_ols_outsider \n",
    "\n",
    "y_tests      = res[\"y_tests\"]\n",
    "permno_list  = res[\"permno\"]\n",
    "month_list   = res[\"month\"]\n",
    "cik_list     = res[\"cik\"]\n",
    "prc_list     = res[\"prc\"]\n",
    "shrout_list  = res[\"shrout\"]\n",
    "mktcap_list  = res[\"mktcap_lag\"]\n",
    "\n",
    "# Flatten everything\n",
    "y_true      = np.concatenate([y for (y, _) in y_tests])\n",
    "y_pred      = np.concatenate([yhat for (_, yhat) in y_tests])\n",
    "permno      = np.concatenate(permno_list)\n",
    "months      = pd.to_datetime(np.concatenate(month_list))\n",
    "cik         = np.concatenate(cik_list)\n",
    "prc         = np.concatenate(prc_list)\n",
    "shrout      = np.concatenate(shrout_list)\n",
    "mktcap_lag  = np.concatenate(mktcap_list)\n",
    "\n",
    "# Output dataset\n",
    "df_ols_outsider = pd.DataFrame({\n",
    "    \"month\":           months,\n",
    "    \"cik\":             cik,\n",
    "    \"permno\":          permno,\n",
    "    \"ret_excess\":      y_true,          \n",
    "    \"prc\":             prc,\n",
    "    \"shrout\":          shrout,\n",
    "    \"mktcap_lag\":      mktcap_lag,\n",
    "    \"pred_ret_excess\": y_pred,          \n",
    "})\n",
    "\n",
    "print(\"\\n===== OLS + OUTSIDER output preview =====\")\n",
    "print(df_ols_outsider.head())\n",
    "print(\"=========================================\\n\")\n",
    "\n",
    "# Save .parquet\n",
    "df_ols_outsider.to_parquet(\"ols_outsider_output.parquet\", index=False)\n",
    "print(\"Saved ols_outsider_output.parquet\")\n",
    "\n",
    "# ---- Save R² (full + per-window) ----\n",
    "r2_metrics_outsider = {\n",
    "    \"model\": \"ols + outsider\",\n",
    "    \"R2_full\": float(res[\"R2_full\"]),\n",
    "    \"R2_window\": {k: float(v) for k, v in res[\"r2_window\"].items()},\n",
    "    \"start_year\": res[\"start_year\"],\n",
    "    \"end_year\": res[\"end_year\"],\n",
    "    \"features\": res[\"features\"],\n",
    "}\n",
    "\n",
    "with open(\"ols_outsider_R2.json\", \"w\") as f:\n",
    "    json.dump(r2_metrics_outsider, f, indent=2)\n",
    "\n",
    "print(\"Saved ols_outsider_R2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2735636",
   "metadata": {},
   "source": [
    "## OLS with insider trading (Insider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline data path\n",
    "path = \"/work/Thesis/Data/3. Insider/with_insider.parquet\"\n",
    "\n",
    "res_ols_insider = OLS_regression(\n",
    "    path=path,  \n",
    "    features=[\"char_mvel1\", \n",
    "    \"char_mom12m\",\n",
    "    \"char_bm\",\n",
    "    \"is_txn_purchase_x_is_tit_ceo\",\n",
    "    \"is_txn_purchase_x_is_tit_cfo\",\n",
    "    \"is_txn_purchase_x_is_tit_coo\",\n",
    "    \"is_txn_purchase_x_is_tit_director\",\n",
    "    \"is_txn_purchase_x_is_tit_other_officer\",\n",
    "    \"is_txn_purchase_x_is_tit_vice_president\",\n",
    "    \"is_txn_sell_x_is_tit_ceo\",\n",
    "    \"is_txn_sell_x_is_tit_ten_percent_owner\",\n",
    "    \"is_opp_buy\",\n",
    "    \"is_opp_sell\",\n",
    "    \"is_rtn_buy\",\n",
    "    \"is_rtn_sell\",\n",
    "    \"is_npr_volume\",\n",
    "    \"is_net_cluster\",\n",
    "    ],\n",
    "    use_all_features=False,\n",
    "    target=\"ret_excess\",\n",
    "    start_year=2005,\n",
    "    end_year=2021,\n",
    "    train_size=60,\n",
    "    val_size=36,\n",
    "    test_size=12,\n",
    "    step_size=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Rename for convenience\n",
    "res = res_ols_insider\n",
    "\n",
    "y_tests      = res[\"y_tests\"]\n",
    "permno_list  = res[\"permno\"]\n",
    "month_list   = res[\"month\"]\n",
    "cik_list     = res[\"cik\"]\n",
    "prc_list     = res[\"prc\"]\n",
    "shrout_list  = res[\"shrout\"]\n",
    "mktcap_list  = res[\"mktcap_lag\"]\n",
    "\n",
    "# Flatten everything\n",
    "y_true      = np.concatenate([y for (y, _) in y_tests])\n",
    "y_pred      = np.concatenate([yhat for (_, yhat) in y_tests])\n",
    "permno      = np.concatenate(permno_list)\n",
    "months      = pd.to_datetime(np.concatenate(month_list))\n",
    "cik         = np.concatenate(cik_list)\n",
    "prc         = np.concatenate(prc_list)\n",
    "shrout      = np.concatenate(shrout_list)\n",
    "mktcap_lag  = np.concatenate(mktcap_list)\n",
    "\n",
    "# Output dataset\n",
    "df_ols_insider = pd.DataFrame({\n",
    "    \"month\":           months,\n",
    "    \"cik\":             cik,\n",
    "    \"permno\":          permno,\n",
    "    \"ret_excess\":      y_true,          \n",
    "    \"prc\":             prc,\n",
    "    \"shrout\":          shrout,\n",
    "    \"mktcap_lag\":      mktcap_lag,\n",
    "    \"pred_ret_excess\": y_pred,          \n",
    "})\n",
    "\n",
    "print(\"\\n===== OLS + INSIDER output preview =====\")\n",
    "print(df_ols_insider.head())\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "# Save .parquet\n",
    "df_ols_insider.to_parquet(\"ols_insider_output.parquet\", index=False)\n",
    "print(\"Saved ols_insider_output.parquet\")\n",
    "\n",
    "# ---- Save R² (full + per-window) ----\n",
    "r2_metrics_insider = {\n",
    "    \"model\": \"ols + insider\",\n",
    "    \"R2_full\": float(res[\"R2_full\"]),\n",
    "    \"R2_window\": {k: float(v) for k, v in res[\"r2_window\"].items()},\n",
    "    \"start_year\": res[\"start_year\"],\n",
    "    \"end_year\": res[\"end_year\"],\n",
    "    \"features\": res[\"features\"],\n",
    "}\n",
    "\n",
    "with open(\"ols_insider_R2.json\", \"w\") as f:\n",
    "    json.dump(r2_metrics_insider, f, indent=2)\n",
    "\n",
    "print(\"Saved ols_insider_R2.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
